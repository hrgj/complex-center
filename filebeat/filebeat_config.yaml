apiVersion: v1
data:
  filebeat.yml: |-
    filebeat.autodiscover:
      providers:
        - type: kubernetes
          templates:
            - condition:
                or:
                  - equals:
                      kubernetes.namespace: gray
                  - equals:
                      kubernetes.namespace: prod
              config:
                - type: filestream
                  id: container-${data.kubernetes.container.id}
                  prospector.scanner.symlinks: true
                  close.on_state_change.removed: false
                  ignore_older: 10m
                  clean_removed: true
                  clean_inactive: 60m
                  parsers:
                    - container: ~
                    - multiline:
                        type: pattern
                        pattern: '^[[:space:]]+(at\b|\.{3}\s)|^Caused by:|^[a-zA-Z][a-zA-Z0-9_$.]*Exception:|^Exception in thread'
                        negate: false
                        match: after
                        timeout: 10s
                  paths:
                    - /var/log/containers/*-${data.kubernetes.container.id}.log
                  harvester:
                    scan_frequency: 10s      # 采集器扫描间隔
                    max_bytes: 10485760      # 单次读取最大字节（10MB）
                    timeout: 30s             # 读取超时时间
                    backoff: 1s              # 文件无新内容时的等待时间
                    max_backoff: 10s         # 最大等待时间
                    backoff_factor: 2        # 退避因子
                  processors:
                    - drop_event:
                        when:
                          or:
                            - not:
                                regexp:
                                  message: '^\|'
                            - contains:
                                message: "==> Preparing:"
                            - contains:
                                message: "==> Parameters:"
                            - contains:
                                message: "JDBC Connection ["
                            - regexp:
                                message: '^\[DEBUG\].*BaseJdbcLogger'
                    - drop_fields:
                        fields:
                          # - "message"
                          - "log"
                          - "fields"
                          - "input"
                          - "ecs"
                          - "fields"
                          - "kubernetes.node.labels"
                          - "kubernetes.replicaset.name"
                          - "kubernetes.pod.uid"
                          - "kubernetes.namespace_uid"
                          - "kubernetes.node.uid"
                          - "kubernetes.namespace_labels"
                          - "kubernetes.labels"
                          - "_ignored"
                          - "_score"
                          - "_index"
                          - "event.original"
                          - "_source"
                    # 1. 过滤非管道符日志
                    # - if:
                    #     not:
                    #       contains:
                    #         message: "|"
                    #   then:
                    #     - drop_event: {}
                    # 2. 使用 dissect 解析
                    # - dissect:
                    #     tokenizer: "|%{level}|%{traceId}|%{user_ip}|%{server_ip}|%{user_code}|%{user_name}|%{site_code}|%{site_name}|%{app_name}|%{timestamp}|%{thread}|%{path}|%{method}|%{content}"
                    #     field: "message"
                    #     target_prefix: ""
                    #     overwrite_keys: true
                    #     ignore_failure: true
                    #     # trim_chars: "\r\n\t "
                    # - timestamp:
                    #     field: "timestamp"
                    #     layouts:
                    #       - "yyyy-MM-dd HH:mm:ss.SSS"
                    #       - "yyyy-MM-dd HH:mm:ss"
                    #     timezone: "Asia/Shanghai"
                    #     ignore_failure: true
                    #     ignore_missing: true
                    # - drop_fields:
                    #     fields: ["message"]
                    #     ignore_missing: true


    # output.elasticsearch:
    #   hosts: ['${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}']
    #   username: ${ELASTICSEARCH_USERNAME}
    #   password: ${ELASTICSEARCH_PASSWORD}
    #   ssl.certificate_authorities: ["/etc/ssl/elasticsearch/ca.crt"]
    #   indices:
    #     - index: "test-%{+yyyy.MM.dd}"
    output.logstash:
      # 核心：Logstash的地址（可以配置多个，实现负载均衡）
      hosts: ["172.20.2.14:5045"]
      timeout: 5
      bulk_max_size: 2048
      # 可选：启用TLS加密传输（如果Logstash配置了SSL/TLS）
      # ssl.enabled: true
      # ssl.certificate_authorities: ["/etc/filebeat/certs/ca.crt"]
      # 可选：重连策略（默认自动重连，可指定重连间隔）
      backoff.init: 1s
      backoff.max: 10s
kind: ConfigMap
metadata:
  creationTimestamp: "2025-12-17T09:26:21Z"
  managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:data:
          .: {}
          f:filebeat.yml: {}
      manager: tke-platform-api
      operation: Update
      time: "2025-12-17T09:27:14Z"
  name: filebeat-config
  namespace: logging
  resourceVersion: "9749664926"
  uid: a4ea3edf-43b1-458a-b560-68fedcc03a2f
